{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f4fa1dd",
   "metadata": {},
   "source": [
    "# [SITE ] [STARTYEAR - ENDYEAR]: Combing New and Old Datasets\n",
    "ANALYST NAME | DATE\n",
    "\n",
    "This notebook facilitates joining the old dataset with the new dataset (accounting for potentially disimilar labels). For backwards compatability, in the event the old and new datsets overlap in time, we join the new dataset with the end of the old dataset, trimming overlapping data from the new dataset. \n",
    "\n",
    "\n",
    "Once all steps have been completed, a single .csv file with the following quantities will be generated (and will span the entire period for which data is available across both the new and old file).\n",
    "* date and time (UTC)\n",
    "* vented pressure, cm\n",
    "* raw pressure, cm\n",
    "* barocorrected pressure, cm\n",
    "* adjusted stage, cm\n",
    "* estimated discharge, cms\n",
    "* water temperature, degrees C\n",
    "* discharge flag\n",
    "\n",
    "Author of Template and Underlying Code: Joe Ammatelli | (jamma@uw.edu) | August 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5b2464",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import timedelta\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(os.path.join('..', '..', 'src')))\n",
    "\n",
    "import config\n",
    "import level_baro_utils\n",
    "\n",
    "sys.path.remove(os.path.abspath(os.path.join('..', '..', 'src')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1fa889",
   "metadata": {},
   "source": [
    "## Configure Plotting Preferences\n",
    "**Analyst TODO:**\n",
    "* Choose plotting backend:\n",
    "    - Interactive (recommended): uncomment `%matplotlib notebook` and `FIGSIZE=NONE`; comment out `FIGSIZE = config.FIGSIZE`\n",
    "    - Inline: comment out `%matplotlib notebook` `FIGSIZE=NONE`; uncomment `FIGSIZE = config.FIGSIZE`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cb5781",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "FIGSIZE=None\n",
    "\n",
    "#FIGSIZE = config.FIGSIZE\n",
    "\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff25965e",
   "metadata": {},
   "source": [
    "## Specify site code and define start/end years of new series\n",
    "**Analyst TODO**:\n",
    "* assign an integer representing the site to the variable `sitecode`. Mappings are as follows (follows from upstream to downstream):\n",
    "    * 0 : Lyell Below Maclure\n",
    "    * 1 : Lyell Above Twin Bridges\n",
    "    * 2 : Dana Fork at Bug Camp\n",
    "    * 3 : Tuolumne River at Highway 120\n",
    "    * 4 : Budd Creek\n",
    "    * 5 : Delaney Above PCT\n",
    "* assign an integer (format 'YYYY') representing the first year of data collection to `start_year`\n",
    "* assign an integer (format 'YYYY') representing the last year of data collection to `end_year`\n",
    "\n",
    "These input parameters are used to automatically retrieve the postprocessed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ee080e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sitecode = 0\n",
    "\n",
    "start_year = 2019\n",
    "end_year = 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b4e44b",
   "metadata": {},
   "source": [
    "## Read in both datasets\n",
    "**Analyst TODO:** Ensure each column is appropriate datatype, correct as necessary by mapping column number to datatype in dictionary called `dtypes` and calling `choose_column_dtype` function (can leave `dtypes` as empty dictionary otherwise); ensure there is a column in the old table for each column of the new table, add new columns as necessary; inspect the resultant tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa35c851",
   "metadata": {},
   "source": [
    "**Old Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7957a881",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_fn = 'Lyell_blw_Maclure_timeseries_stage_Q_T_2005_2018.csv'\n",
    "old_path = os.path.join('..', '..', 'compiled_data', 'published', old_fn)\n",
    "old_df = pd.read_csv(old_path, index_col=0, parse_dates=[0], infer_datetime_format=True, na_values=[' NaN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b0680b",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015a88c2",
   "metadata": {},
   "source": [
    "Explicity choose datatype for incorrect columns of interest (read_csv sometimes chooses wrong datatype for some columns and won't allow me to convert from certain types to others) -- This step should not be necessary for future processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18514817",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = {3:np.float64,\n",
    "          4:np.float64}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16643e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_df = level_baro_utils.choose_column_dtype(old_df, dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6040860d",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7802b48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6708e4",
   "metadata": {},
   "source": [
    "**New Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf09844",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_fn = config.FINAL_OUTPUT_FN.format(site=config.SITE_SHORTNAME[sitecode],\n",
    "                                       start=start_year,\n",
    "                                       end=end_year)\n",
    "\n",
    "new_path = os.path.join('..', '..', 'stitch_discharge', 'data', 'processed', new_fn)\n",
    "\n",
    "new_df = pd.read_csv(new_path, index_col=0, parse_dates=[0], infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e447f51",
   "metadata": {},
   "source": [
    "Inspect resultant tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66c5a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f902b60",
   "metadata": {},
   "source": [
    "## If the old dataset has different column names than the new dataset, map the old names to the new ones\n",
    "This step exists to compensate for different header labels used in prior datasets. Moving forward (as of the release of the first version of this processing suite, attempts are made to have a consisistent labelling scheme so that this step is not necessary in the future)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18414c1",
   "metadata": {},
   "source": [
    "### Specify the old label names\n",
    "**Analyst TODO**:\n",
    "If the old dataset uses different header names, defines of the header names in the appropriate variable below (leave as empty string otherwise).\n",
    "\n",
    "e.g.\n",
    "* if the old dataset uses the label `stage (cm)` to describe the offset stage value, set the variable `adjusted_stage_label` equal to `stage (cm)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d379889",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_pressure_label = ' raw_pressure(cm)'\n",
    "barocorrected_pressure_label = ' barocorrected_pressure(cm)'\n",
    "adjusted_stage_label = ' stage(cm)'\n",
    "estimated_discharge_label = ' estimated_discharge(cms)'\n",
    "water_temperature_label = ' water_temperature(deg_C)'\n",
    "discharge_flag_label = ' discharge flag'\n",
    "\n",
    "old_labels = [raw_pressure_label, \n",
    "              barocorrected_pressure_label, \n",
    "              adjusted_stage_label, \n",
    "              estimated_discharge_label,\n",
    "              water_temperature_label,\n",
    "              discharge_flag_label]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad7b340",
   "metadata": {},
   "source": [
    "### Update the header of the old dataset dataframe to match the header of the new dataset dataframe\n",
    "**Analyst TODO:** Run cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbc9999",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_df = level_baro_utils.map_old_labels_2_new(old_df, old_labels)\n",
    "old_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5badd2bf",
   "metadata": {},
   "source": [
    "## Join the old data frame with the new dataframe (only the columns they have in common: namely the labels listed in the previous step)\n",
    "**Analyst TODO:** Run cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb14985d",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultant_df, boundary = level_baro_utils.join_dataframes(old_df, new_df)\n",
    "\n",
    "# may need to override datatype of some columns\n",
    "resultant_df['estimated_discharge(cms)'] = resultant_df['estimated_discharge(cms)'].astype(np.float64)\n",
    "\n",
    "resultant_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8b2164",
   "metadata": {},
   "source": [
    "## Inspect result around boundary of old/new dataset\n",
    "**Analyst TODO** Inspect the results. Verify boundary of new and old series does not have duplicated values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ff39ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultant_df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60102942",
   "metadata": {},
   "outputs": [],
   "source": [
    "level_baro_utils.plot_boundary(resultant_df, boundary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f491eab2",
   "metadata": {},
   "source": [
    "## Save Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04971211",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_year = old_df.index[0].year\n",
    "last_year = new_df.index[-1].year\n",
    "\n",
    "level_baro_utils.save_final_data(resultant_df, sitecode, first_year, last_year)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
