{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e560b751",
   "metadata": {},
   "source": [
    "# [SITE] [Start Year/End Year] Vented Data Post Processing\n",
    "ANALYST | DATE\n",
    "\n",
    "This notebook documents the steps taken to clean vented pressure transducer time series. In particular, this notebook faciliates the following postprocessing/quality control steps:\n",
    "1. Inspection of the raw data\n",
    "2. Conversion of the time series to the correct units\n",
    "3. Resampling from 15 minutes to 30 minutes (to match the unvented levelogger time series)\n",
    "4. Selection of a desired time span (from time series that often span many year)\n",
    "6. Flagging of Ice Jams, sensor malfunctions, or sensor shifts\n",
    "7. Identification and sensor shifts\n",
    "\n",
    "Once all steps have been completed, a .csv file with the following quantities will be generated for each contiguous segment (period in the time series where there are no obvious sensor shifts):\n",
    "* Date and time (UTC)\n",
    "* vented pressure, cm\n",
    "* water temperature, degrees C\n",
    "* discharge flag\n",
    "\n",
    "Author of Template and Underlying Code: Joe Ammatelli | (jamma@uw.edu) | May 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4976fe",
   "metadata": {},
   "source": [
    "## Import Relevant Libraries and Set Plotting Theme\n",
    "**Analyst TODO**: Run cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80758079",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import timedelta\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(os.path.join('..', '..', 'src')))\n",
    "\n",
    "import config\n",
    "import level_baro_utils\n",
    "\n",
    "sys.path.remove(os.path.abspath(os.path.join('..', '..', 'src')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f59a095",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ae6840",
   "metadata": {},
   "source": [
    "## Specify Site and Data Path\n",
    "* assign an integer representing the site to the variable `sitecode`. Mappings are as follows (follows from upstream to downstream):\n",
    "    * 0 : Lyell Below Maclure\n",
    "    * 1 : Lyell Above Twin Bridges\n",
    "    * 2 : Dana Fork at Bug Camp\n",
    "    * 3 : Tuolumne River at Highway 120\n",
    "    * 4 : Budd Creek\n",
    "    * 5 : Delaney Above PCT\n",
    "* assign a string representing the file name to the `vented_fn` variable (note only the file name is needed, not the path to the file)\n",
    "\n",
    "These input parameters are used to automatically retrieve the correct raw data, populate the correct log file, label any plots with relevant site descriptors, and automatically write output with descriptive names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c306e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "sitecode = 0\n",
    "\n",
    "vented_fn = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d0dfab",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "**Analyst TODO**: \n",
    "* Modify the `pd.read_csv` function as appropriate for the given vented series (reading the data has not been abstracted away since the input vented pressure transducer time series often have different formatting). In particular, you may need to edit the `header`, `skiprows`, `index_col`, and `parse_dates` parameters. See the [pandas documentation](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html) for more details.\n",
    "* Inspect the column labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829ceaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vented_path = os.path.join('..', 'data', 'raw', vented_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96379ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vented_df = pd.read_csv(vented_path, \n",
    "                        header=1, \n",
    "                        skiprows=[2,3], \n",
    "                        index_col=0, \n",
    "                        parse_dates=[0], \n",
    "                        infer_datetime_format=True)\n",
    "\n",
    "vented_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5449cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vented_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f587ab4d",
   "metadata": {},
   "source": [
    "## Define Name of Level Field\n",
    "**Analyst TODO**: Create a mapping between the level header in the original file and the naming convention used elsewhere in the processing.\n",
    "* assign a string representing the name of the column storing level data to the variable `original_lvl_field_name`\n",
    "* You should not need to modify the variable `new_lvl_field_name`\n",
    "* NOTE: There is usually a column for raw level readings and corrected level measurements, which are tuned during each site visit by the Tuolumne staff. Discuss which column to use with Jessica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36be2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_lvl_field_name = ''\n",
    "new_lvl_field_name = 'lvl_cm'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f692c4e",
   "metadata": {},
   "source": [
    "## Convert to Correct Time Zone and Units\n",
    "**Analyst TODO**: Verify correct conversions are being applied (default is to convert level from FT to CM and convert time from PDT to UTC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07676251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert ft to cm and local time to UTC\n",
    "vented_df[original_lvl_field_name] *= level_baro_utils.FT_TO_CM\n",
    "vented_df.rename(columns={original_lvl_field_name:new_lvl_field_name}, inplace=True)\n",
    "vented_df.sort_index(inplace=True)\n",
    "vented_df.index = vented_df.index + timedelta(hours=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6731c67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vented_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055bbc0d",
   "metadata": {},
   "source": [
    "## Resample (go from 15 minute data to 30 minute data)\n",
    "**Analyst TODO**: Run cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a17ffa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vented_df = level_baro_utils.resample_vented(vented_df)\n",
    "vented_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd4794f",
   "metadata": {},
   "source": [
    "## Define the Time Range to Extract Data From and Post-Process\n",
    "**Analyst TODO**: Choose the time range of interest (should cover the same years as the unprocessed Solinst levelogger datasets)\n",
    "* assign a string representing the start date of trimmed time series to the variable `start` (format 'YYYY-MM-DD', e.g. 2018-06-01)\n",
    "* assign a string representing the span of trimmed time series to the variable `span` (format 'YY-YY', e.g. 18-21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64519ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'YYYY-MM-DD'\n",
    "start = ''\n",
    "\n",
    "# 'YY-YY'\n",
    "span = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d082781e",
   "metadata": {},
   "outputs": [],
   "source": [
    "site_info = {'sitecode' : sitecode, \n",
    "             'site' : config.SITE_LONGNAME[sitecode], \n",
    "             'span' : span}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d4f1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vented_range_df = vented_df[start:]\n",
    "vented_range_ds = vented_range_df[new_lvl_field_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d89d531",
   "metadata": {},
   "source": [
    "## Isolate Temperature Data\n",
    "**Analyst TODO**:\n",
    "* Assign a string representing the name of the column temperature data to the variable `temp_field_name`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f690c88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_field_name = ''\n",
    "\n",
    "temp_C_ds = vented_range_df[temp_field_name]\n",
    "temp_C_ds.plot(ylabel='cm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f700e3a",
   "metadata": {},
   "source": [
    "## Inspect Time Range of Interest\n",
    "**Analyst TODO**: Examine the time series a identify possible ice jams, sensor malfunctions, and sensor shifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c031b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "level_baro_utils.plot_multiple_pres_timeseries([vented_range_ds], [''], site_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc9399a",
   "metadata": {},
   "source": [
    "## Inspect and Flag Ice Jams\n",
    "**Analyst TODO**: Inspect all potential ice jams and sensor shifts. After all jams/shifts have been evaluated, add confirmed ice jams and sensor shifts to the appropriate list. \n",
    "1. For each ice jam/sensor shift candidate, create a new cell and encode the start and end date of the candidate. For example:\n",
    "```\n",
    "candidate_1 = {'start':'2018-12-1', 'end':'2018-12-6'}\n",
    "level_baro_utils.plot_candidate(level_trimed_aligned_barocorrected_ds, candidate_1, site_info)\n",
    "```\n",
    "2. Ensure each candidate variable is numbered and that all numbers are unique (easiest to just have ascending numbers for each candidate)\n",
    "3. Ensure the correct candidate is being passed to `level_baro_utils.plot_candidate` (i.e. after copying and pasting code into new cell, update the candidate number in both lines of code).\n",
    "4. Run the cell and nspect the resultant plot.\n",
    "5. If the candidate is determined to be an ice jam or sensor shift, add the candidate name to the approprioate list at the end of the section. If after evaluating all candidates there are no ice jams or sensor_shifts, assign a `None` to the appropriate variabel: e.g.:\n",
    "```\n",
    "ice_jams = [candidate_1]  # there is one ice jam\n",
    "sensor_shifts = None      # there are no sensor shifts\n",
    "```\n",
    "6. **Important**: After deciding whether a segment is an ice jam or sensor shift, make a new Markdown cell below the cells and write record what the decision was and why (along with the date). Also note whether it was verified by Jessica or someone else with lots of domain knowledge/experience. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf9ac60",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_1 = {'start':'', 'end':''}\n",
    "level_baro_utils.plot_candidate(vented_range_ds, candidate_1, site_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba38513",
   "metadata": {},
   "outputs": [],
   "source": [
    "ice_jams = []\n",
    "sensor_malfunctions = []\n",
    "sensor_shifts = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76318e2",
   "metadata": {},
   "source": [
    "## Create New Frame With All Desired Output Variables\n",
    "**Analyst TODO**: Ensure tabular data has correct header fields. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c52e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = level_baro_utils.make_vented_output_df(vented_range_ds.index, \n",
    "                                                   vented_range_ds, \n",
    "                                                   temp_C_ds, \n",
    "                                                   ice_jams, \n",
    "                                                   sensor_malfunctions)\n",
    "output_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ede5960",
   "metadata": {},
   "source": [
    "## Split Series at Sensor Shifts and Save Data\n",
    "**Analyst TODO**: Make sure the number of segments is consistent with the number of sensor shifts defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a70701",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dfs = level_baro_utils.split_series_at_shifts(output_df, sensor_shifts)\n",
    "print(f'Number of segments: {len(output_dfs)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd6fe21",
   "metadata": {},
   "source": [
    "## Save Output Data\n",
    "**Analyst TODO**: Verify correct number of output files and verify file names and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b27c745",
   "metadata": {},
   "outputs": [],
   "source": [
    "level_baro_utils.save_vented_timeseries(output_dfs, site_info)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
