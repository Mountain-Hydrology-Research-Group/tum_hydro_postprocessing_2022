{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "932f4a9a",
   "metadata": {},
   "source": [
    "# [SITE] [YEAR] Solinst Levelogger Post Processing\n",
    "ANALYST NAME | DATE\n",
    "\n",
    "This notebook documents the steps taken to arrive at the barocorrected stage data for a given site (starting from the raw Solinst Levelogger data). In particular, this notebook faciliates the following postprocessing/quality control steps:\n",
    "1. Inspection of the raw data\n",
    "2. Confirmation that the data is in UTC\n",
    "3. Trimming of the data to the times when it was actively deployed (in the water)\n",
    "4. Standardizing of the time series to such that all samples fall on the hour or half-hour\n",
    "5. Barocorrection (compensation for atmospheric pressure in unvented Solinst Levelogger data)\n",
    "6. Flagging of Ice Jams\n",
    "7. Identification and sensor shifts\n",
    "\n",
    "Once all steps have been completed, a .csv file with the following quantities will be generated for each contiguous segment (period in the time series where there are no obvious sensor shifts):\n",
    "* Date and time (UTC)\n",
    "* raw pressure, cm\n",
    "* barocorrected pressure, cm\n",
    "* water temperature, degrees C\n",
    "* discharge flag\n",
    "\n",
    "Author of Template and Underlying Code: Joe Ammatelli | (jamma@uw.edu) | May 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81be6842",
   "metadata": {},
   "source": [
    "## Import Relevant Libaries\n",
    "**Analyst TODO**: Nothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369000c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import seaborn as sns\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(os.path.join('..', '..', 'src')))\n",
    "\n",
    "import config\n",
    "import level_baro_utils\n",
    "import log_utils\n",
    "\n",
    "sys.path.remove(os.path.abspath(os.path.join('..', '..', 'src')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836b815a",
   "metadata": {},
   "source": [
    "## Specify Site Information\n",
    "**Analyst TODO**:\n",
    "* assign an integer representing the site to the variable `sitecode`. Mappings are as follows (follows from upstream to downstream):\n",
    "    * 0 : Lyell Below Maclure\n",
    "    * 1 : Lyell Above Twin Bridges\n",
    "    * 2 : Dana Fork at Bug Camp\n",
    "    * 3 : Tuolumne River at Highway 120\n",
    "    * 4 : Budd Creek\n",
    "    * 5 : Delaney Above PCT\n",
    "* assign a string (format 'YYYY') representing the collection year of the data to the variable `collection_year`\n",
    "* assign a string (format 'YY/YY') representing the span in years of the data to the variable `span`\n",
    "\n",
    "These input parameters are used to automatically retrieve the correct raw data, populate the correct log file, label any plots with relevant site descriptors, and automatically write output with descriptive names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a8881d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example: site is Budd Creek, data was collected in 2019, and the data spanned 2018 and 2019\n",
    "# sitecode = 4\n",
    "# collection_year = '2019'\n",
    "# span = '18/19'\n",
    "\n",
    "sitecode = None\n",
    "collection_year = ''\n",
    "span = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe5e4ea",
   "metadata": {},
   "source": [
    "## Set Plot Settings and Compile Site Information\n",
    "**Analyst TODO**: Nothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d88a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2309bac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "site_info = {'sitecode':sitecode,\n",
    "             'site':config.SITE_LONGNAME[sitecode],\n",
    "             'collection_year':collection_year,\n",
    "             'span':span}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a300501f",
   "metadata": {},
   "source": [
    "## Load and Inspect Raw Data\n",
    "**Analyst TODO**: Examine the tabular data and time series plots. Confirm all desired data is present. Note any glaring irregularities in the time series. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d497dabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "level_path = os.path.join('..', 'data', 'normalized_raw', f'lvl_{config.SITE_SHORTNAME[sitecode]}_{collection_year}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ed5514",
   "metadata": {},
   "outputs": [],
   "source": [
    "level_df = level_baro_utils.load_normalized_solinst_data(level_path)\n",
    "level_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd76035f",
   "metadata": {},
   "outputs": [],
   "source": [
    "level_baro_utils.plot_solinst_pressure_temp(level_df, site_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468d4e69",
   "metadata": {},
   "source": [
    "## Verify UTC\n",
    "**Analyst TODO**: \n",
    "* Choose small range (1-3 days) to observe temperature swings. If possible, choose a range when stream is dry (as determined by inspecting time lapse imagery and field notes).\n",
    "* Assign a string representing the start date (format 'YYYY-MM_DD') to the `tz_start_date` variable\n",
    "* Assign a string representing the end date (format 'YYYY-MM_DD') to the `tz_end_date` variable\n",
    "* Run the next two cells and confirm temperature peaks algin with expected time of day in UTC\n",
    "* Conclude as to whether the data is in UTC and write a comment in the string assigned ot `utc_note`. E.g:\n",
    "```\n",
    "utc_note = 'Temp peaks around 23:00 (4:00PM local time). Conclude data is in UTC'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d968a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example\n",
    "# tz_start_date = '2018-9-26'\n",
    "# tz_end_date = '2018-9-27'\n",
    "\n",
    "tz_start_date = ''\n",
    "tz_end_date = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31065dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "level_baro_utils.plot_temp_interval(level_df, tz_start_date, tz_end_date, site_info, label='Temperature/Timezone Comparison')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a969b7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "utc_note = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f412cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(utc_note)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff025317",
   "metadata": {},
   "source": [
    "## Trim\n",
    "**Analyst TODO**: \n",
    "* assign a string (format 'YYYY-MM-DD HH:MM') representing the date and time (UTC) the sensor was deployed in the water to the variable `insert_datetime` (reasonable to begin with times recorded in field notes)\n",
    "* assign a string (format 'YYYY-MM-DD HH:MM') representing the date and time (UTC) the sensor was removed from the water to the variable `remove_datetime` (reasonable to begin with times recorded in field notes)\n",
    "* inspect the resultant plots and adjust `insert_datetime` and `remove_datetime` as needed to capture the true period the sensor was in the water\n",
    "* **Note**: In most cases there is a pronounced, sudden change in both temperature and pressure when the sensor is inserted/removed. Use this to guide tuning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ebd7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example\n",
    "# insert_datetime = '2018-08-1 17:20'\n",
    "# remove_datetime = '2019-08-14 16:00'\n",
    "\n",
    "insert_datetime = ''\n",
    "remove_datetime = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95238934",
   "metadata": {},
   "outputs": [],
   "source": [
    "level_baro_utils.plot_in_water(level_df, insert_datetime, remove_datetime, site_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25a6487",
   "metadata": {},
   "source": [
    "## Trim Time Series\n",
    "**Analyst TODO**: Observe the resultant plot and confirm the data was trimmed properly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8895bd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "level_trim_df = level_baro_utils.trim_df(level_df, insert_datetime, remove_datetime, site_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fdd509",
   "metadata": {},
   "source": [
    "## Load Barometric Pressure Data\n",
    "**Analyst TODO**:\n",
    "* assign a string to the variable `baro_dir` that represents the name of the directory (within the data folder) where the barometric pressure file is found (will vary depending on whether Solinst Barologger data, NCAR Reanalysis barometric pressure, or other data is being used).\n",
    "* assign a string to the variable `baro_fn` that represents the name of barometric pressure time series file\n",
    "* choose the appropriate load method for the data source type (`level_baro_utils.load_ncar_baro` for NCAR baro data and `level_baro_utils.load_normalized_solinst_data` for Solinst Barologger data). Additionally, the subsequent plotting method will need to be changed to `level_baro_utils.plot_solinst_pressure_temp(baro_df, baro_site_info, sensor_type='baro')`\n",
    "* inspect tabular data and time series plot to ensure all desired data is present and there are not glaring irregularities in the time series\n",
    "* **Note**: If using Solinst Barologger data, define a new site_info dictionary with the sitename and same time variables defined earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21dcd100",
   "metadata": {},
   "outputs": [],
   "source": [
    "baro_dir = ''\n",
    "baro_fn = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372e6238",
   "metadata": {},
   "outputs": [],
   "source": [
    "baro_path = os.path.join('..', 'data', baro_dir, baro_fn)\n",
    "\n",
    "# Analyst TODO: choose appropriate load method\n",
    "baro_df = level_baro_utils.load_ncar_baro(baro_path)\n",
    "# baro_df = level_baro_utils.load_normalized_solinst_data(baro_path)\n",
    "\n",
    "baro_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf80a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "level_baro_utils.plot_ncar_baro(baro_df, site_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a7143a",
   "metadata": {},
   "source": [
    "## Interpolate Level and Baro to Same Time Stamps\n",
    "**Analyst TODO**: Inspect plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea48cd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "spanning_index = level_baro_utils.get_30min_spanning_index(level_trim_df)\n",
    "level_interp_df = level_baro_utils.interpolate_to_timeseries(spanning_index, level_trim_df)\n",
    "baro_interp_df = level_baro_utils.interpolate_to_timeseries(spanning_index, baro_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0765cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "series = [level_interp_df['lvl_cm'], baro_interp_df['baro_cm']]\n",
    "labels = ['Raw Level', 'Barometric Pressure']\n",
    "level_baro_utils.plot_multiple_pres_timeseries(series, labels, site_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94eec67a",
   "metadata": {},
   "source": [
    "## Barocorrect Level Data\n",
    "**Analyst TODO**: Inspect plots. Barocorrected level should be considerably smoother at large time scales than before. There should be clean diurnal swings in pressure as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81341555",
   "metadata": {},
   "outputs": [],
   "source": [
    "level_trimed_aligned_barocorrected_ds = level_baro_utils.barocorrect_level(level_interp_df, baro_interp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55908b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "series = [level_trimed_aligned_barocorrected_ds, level_interp_df['lvl_cm'], baro_interp_df['baro_cm']]\n",
    "labels = ['Barocorrected Level', 'Raw Level', 'Barometric Pressure']\n",
    "level_baro_utils.plot_multiple_pres_timeseries(series, labels, site_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf268dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "level_baro_utils.plot_pres_multiple_interval(level_trimed_aligned_barocorrected_ds,\n",
    "                            'Barocorrected Level', \n",
    "                            site_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30ff7ac",
   "metadata": {},
   "source": [
    "## Flag Ice Jams, Split Series When Sensor Shifts\n",
    "**Analyst TODO**: Inspect all potential ice jams and sensor shifts. After all jams/shifts have been evaluated, add confirmed ice jams and sensor shifts to the appropriate list. \n",
    "1. For each ice jam/sensor shift candidate, create a new cell and encode the start and end date of the candidate. For example:\n",
    "```\n",
    "candidate_1 = {'start':'2018-12-1', 'end':'2018-12-6'}\n",
    "level_baro_utils.plot_candidate(level_trimed_aligned_barocorrected_ds, candidate_1, site_info)\n",
    "```\n",
    "2. Ensure each candidate variable is numbered and that all numbers are unique (easiest to just have ascending numbers for each candidate)\n",
    "3. Ensure the correct candidate is being passed to `level_baro_utils.plot_candidate` (i.e. after copying and pasting code into new cell, update the candidate number in both lines of code).\n",
    "4. Run the cell and nspect the resultant plot.\n",
    "5. If the candidate is determined to be an ice jam or sensor shift, add the candidate name to the approprioate list at the end of the section. If after evaluating all candidates there are no ice jams or sensor_shifts, assign a `None` to the appropriate variabel: e.g.:\n",
    "```\n",
    "ice_jams = [candidate_1]  # there is one ice jam\n",
    "sensor_shifts = None      # there are no sensor shifts\n",
    "```\n",
    "6. **Important**: After deciding whether a segment is an ice jam or sensor shift, make a new Markdown cell below the cells and write record what the decision was and why (along with the date). Also note whether it was verified by Jessica or someone else with lots of domain knowledge/experience. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d45cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_1 = {'start':'', 'end':''}\n",
    "level_baro_utils.plot_candidate(level_trimed_aligned_barocorrected_ds, candidate_1, site_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8178ab8f",
   "metadata": {},
   "source": [
    "**Verdict**: WRITE VERDICT, DATE, and REASONING HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1049b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "ice_jams = None\n",
    "sensor_shifts = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4df4f1c",
   "metadata": {},
   "source": [
    "## Create New Frame With All Desired Output Variables\n",
    "**Analyst TODO**: Ensure tabular data has correct header fields. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5419bc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = level_baro_utils.make_output_df(level_interp_df.index, \n",
    "                                            level_interp_df['lvl_cm'],\n",
    "                                            level_trimed_aligned_barocorrected_ds,\n",
    "                                            level_interp_df['temp_C'],\n",
    "                                            ice_jams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bcd57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade3fa7a",
   "metadata": {},
   "source": [
    "## Split Series at Sensor Shifts and Save Data\n",
    "**Analyst TODO**: Make sure the number of segments is consistent with the number of sensor shifts defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044b2806",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dfs = level_baro_utils.split_series_at_shifts(output_df, sensor_shifts)\n",
    "print(f'Number of segments: {len(output_dfs)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6955afb",
   "metadata": {},
   "source": [
    "## Save Output Data\n",
    "**Analyst TODO**: Verify correct number of output files and verify file names and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb78445",
   "metadata": {},
   "outputs": [],
   "source": [
    "level_baro_utils.save_barocorrected_timeseries(output_dfs, site_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb3f65b",
   "metadata": {},
   "source": [
    "## Write Summary to Processing Log When Done\n",
    "**Analyst TODO**: \n",
    "* Once done processing the site, assign `True` to `done` and run cell\n",
    "* After writing to log, assign `True` to `wrote_to_log`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49201e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = level_baro_utils.get_summary(level_path, \n",
    "                                      utc_note, \n",
    "                                      baro_path, \n",
    "                                      ice_jams, \n",
    "                                      sensor_shifts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43eb28fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "done = False\n",
    "wrote_to_log = False\n",
    "if done and not wrote_to_log:\n",
    "    log_fn = os.path.join('..', 'logs', f'{config.SITE_SHORTNAME[sitecode]}_{collection_year}_log.txt')\n",
    "    log_utils.append_to_log(log_fn, 'SOLINST LEVEL POST PROCESSING AND QC', summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
