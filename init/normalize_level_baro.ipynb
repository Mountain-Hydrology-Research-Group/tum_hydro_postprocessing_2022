{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2e34a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(os.path.join('..', 'src')))\n",
    "\n",
    "import config\n",
    "import level_baro_utils\n",
    "import log_utils\n",
    "\n",
    "sys.path.remove(os.path.abspath(os.path.join('..', 'src')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f4f48ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/jamma/Desktop/TuolumneHydroClimate/init',\n",
       " '/Users/jamma/opt/miniconda3/lib/python39.zip',\n",
       " '/Users/jamma/opt/miniconda3/lib/python3.9',\n",
       " '/Users/jamma/opt/miniconda3/lib/python3.9/lib-dynload',\n",
       " '',\n",
       " '/Users/jamma/opt/miniconda3/lib/python3.9/site-packages',\n",
       " '/Users/jamma/opt/miniconda3/lib/python3.9/site-packages/locket-0.2.1-py3.9.egg',\n",
       " '/Users/jamma/opt/miniconda3/lib/python3.9/site-packages/IPython/extensions',\n",
       " '/Users/jamma/.ipython']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e442f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_dir_by_year = {'2021' : '../../tum_21_raw'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec92b497",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************\n",
      "Normalizing Data for Year: 2021\n",
      "*******************************\n",
      "\n",
      "Normalizing ConnessCrk_Barologger_20210812.csv\n",
      "Unable to infer site from given fn\n",
      "Finished Normalizing ConnessCrk_Barologger_20210812.csv\n",
      "\n",
      "Normalizing BugLabBaro_Barologger_20210812.csv\n",
      "Unable to infer site from given fn\n",
      "Finished Normalizing BugLabBaro_Barologger_20210812.csv\n",
      "\n",
      "Normalizing LyellBlwMaclure_Barologger_20210811.csv\n",
      "Finished Normalizing LyellBlwMaclure_Barologger_20210811.csv\n",
      "\n",
      "Normalizing Tuolumne120_Levelogger_20210812.csv\n",
      "Finished Normalizing Tuolumne120_Levelogger_20210812.csv\n",
      "\n",
      "Normalizing DelaneyCrkAbvPCT_Levelogger_20210726.csv\n",
      "Finished Normalizing DelaneyCrkAbvPCT_Levelogger_20210726.csv\n",
      "\n",
      "Normalizing LyellAbvTwinBridges_Levelogger_20210726.csv\n",
      "Finished Normalizing LyellAbvTwinBridges_Levelogger_20210726.csv\n",
      "\n",
      "Normalizing LyellBlwMaclure_Levelogger_20210811.csv\n",
      "Finished Normalizing LyellBlwMaclure_Levelogger_20210811.csv\n",
      "\n",
      "Normalizing DanaFrkBugCamp_Levelogger_20210728.csv\n",
      "Finished Normalizing DanaFrkBugCamp_Levelogger_20210728.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for year in raw_data_dir_by_year:\n",
    "    print('*******************************')\n",
    "    print(f'Normalizing Data for Year: {year}')\n",
    "    print('*******************************\\n')\n",
    "    \n",
    "    # read data from correct year\n",
    "    data_dir = raw_data_dir_by_year[year]\n",
    "    \n",
    "    # write output to correct place\n",
    "    loc_year_dir_path = os.path.join('..', f'unvented_{year}')\n",
    "    \n",
    "    # create directory to store raw data\n",
    "    raw_dir = os.path.join(loc_year_dir_path, 'data', 'raw')\n",
    "    if not os.path.exists(raw_dir):\n",
    "        os.mkdir(raw_dir)\n",
    "    \n",
    "    # create dir to store normalized data\n",
    "    norm_dir = os.path.join(loc_year_dir_path, 'data', 'normalized_raw')\n",
    "    if not os.path.exists(norm_dir):\n",
    "        os.mkdir(norm_dir)\n",
    "    \n",
    "    # normalize each file in directory\n",
    "    for fn in os.listdir(data_dir):\n",
    "        if fn[0] == '.':\n",
    "            continue\n",
    "            \n",
    "        print(f'Normalizing {fn}')\n",
    "        \n",
    "        f_path = os.path.join(data_dir, fn)\n",
    "        \n",
    "        # infer site\n",
    "        sitekey = level_baro_utils.infer_site_from_name(fn)\n",
    "        sitename = None\n",
    "        if sitekey is None:\n",
    "            sitename = fn.split('_')[0]\n",
    "        else:\n",
    "            sitename = config.SITE_SHORTNAME[sitekey]\n",
    "        \n",
    "        # infer sensor type\n",
    "        sensor_type = level_baro_utils.infer_sensor_type_from_name(fn)\n",
    "        \n",
    "        # find header start and read file metadata\n",
    "        meta, header_num = level_baro_utils.read_meta(f_path)\n",
    "        \n",
    "        # read data, convert to desired units, normalize header name\n",
    "        df = level_baro_utils.read_normalize_solinst_data(f_path, header_num, sensor_type)\n",
    "    \n",
    "        # save raw data to\n",
    "        raw_path = os.path.join(raw_dir, fn)\n",
    "        shutil.copyfile(f_path, raw_path)\n",
    "        \n",
    "        # save normalized file according to naming_convention\n",
    "        data_name = config.NORMALIZED_FN.format(sensor_type=sensor_type, \n",
    "                                                sitename=sitename, \n",
    "                                                year=year)\n",
    "        data_path = os.path.join(norm_dir, data_name)\n",
    "        df.to_csv(data_path)\n",
    "        \n",
    "        # create log file for site and append meta data\n",
    "        if sensor_type == 'lvl':\n",
    "            log_dir = os.path.join(loc_year_dir_path, 'logs')\n",
    "            log_name = f'{sitename}_{year}_log.txt'\n",
    "            log_path = os.path.join(log_dir, log_name)\n",
    "            log_utils.create_site_log(log_path, sitename, year)\n",
    "            log_utils.append_to_log(log_path, 'RAW SOLINST META DATA\\n', ''.join(meta))\n",
    "        \n",
    "        print(f'Finished Normalizing {fn}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78edac2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
